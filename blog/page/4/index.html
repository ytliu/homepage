
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Mctrain's Blog</title>
  <meta name="author" content="Liu Yutao">

  
  <meta name="description" content="元旦去奉化享受了，玩得超爽，吃的也超爽！感谢zbd和他爸妈的热情招呼，让我们享受了如此惬意的三天~ 好了，言归正传吧，讲讲这篇paper： "ELI: Bare-Metal Performance for I/O virtualization" 是由IBM和Technion的学者做的， &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://ytliu.github.com/blog/page/4/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="Mctrain's Blog" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Mctrain's Blog</a></h1>
  
    <h2>Security, Virtualization, Network, as well as life moments</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss email">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
    <li><a href="ytliu.cc@gmail.com" rel="subscribe-email" title="subscribe via email">Email</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:ytliu.github.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/01/03/paper-reading-x86-interrupt-and-sr-iov-interrupts-avoidance/">Paper Reading - X86 Interrupt and SR-IOV Interrupts Avoidance</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-01-03T21:37:00+08:00" pubdate data-updated="true">Jan 3<span>rd</span>, 2012</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>元旦去奉化享受了，玩得超爽，吃的也超爽！感谢zbd和他爸妈的热情招呼，让我们享受了如此惬意的三天~</p>

<p>好了，言归正传吧，讲讲这篇paper：</p>

<pre><code>    "ELI: Bare-Metal Performance for I/O virtualization"
</code></pre>

<p>是由IBM和Technion的学者做的，发表在ASPLOS&#8217;12上，按照海波的说法是Muli教授推荐的一篇他们写的paper，现在还没公布出来，拿到的是DRAFT版本，所以不会讲太多的细节，主要是谈谈自己学到的东西吧。</p>

<p>由于这篇paper是自己读的，所以也就看的比较仔细，说实话，看完整篇之后收获真的挺大的，加上之后Muli教授和他的同事对邮件的详细回答让我更加清楚了x86对interrupt的处理，特别是虚拟化环境下的一些细节，加上它最后做出来效果很好，对SR-IOV的优化（特别是万兆网络下小包的效率）提高很大，所以从总体来说我觉得这是一个很有趣而且有用的工作。</p>

<p>先简要介绍下这篇paper的motivation吧：在现在虚拟化的环境中，SR-IOV（single root I/O virtualization）可以说使得整个I/O的效率相对于传统的PV也好，用qemu模拟的HVM也好，提高了一个层次，由于可以将一个特定的device（比如网卡）或者virtual function直接赋予一个domain虚拟机，从而从本质上减少了host（比如xen）在整个I/O路径上的介入时间，同时也减少了相当一部分的内存拷贝操作，使得I/O的performance、latency都得到了提高。但是不管是不是用SR-IOV技术，由于x86体系结构的限制，在由物理设备产生的interrupt发生时还是会陷入host，由host来对interrupt进行第一步的处理，或是直接调用自己的interrupt handler，或是向虚拟机插入软件中断，再调度回虚拟机由虚拟机的interrupt handler处理，在处理完成之后由于对EOI寄存器的写操作还会再一次陷入host；由于这两次的context切换造成的overhead，包括context switch、cache pollution&#8230;也就造成了作者在做evaluation时测出的40%的overhead。（其实刚开始看到这个40%我还觉得挺不可思议的，我们实验室之前也对SR-IOV进行过评估，当时得出的结论是SR-IOV的性能很好，和native的环境几乎没有差别。不过后来发现是因为我们的测试环境是千兆，而作者的环境是万兆，而且是小包~~~看来测试环境的优劣还是很重要啊:-)）。</p>

<p><img src="http://ytliu.github.com/images/2012-01-04-1.png" title="guest/host context switch in interrupt handling" alt="baseline interrupt handle" /></p>

<p>于是乎，这篇paper的作者就提出了ELI（ExitLess Interrupt），其目的就是最大程度地减少由这些interrupt造成的context切换，从而达到性能的最大化。</p>

<p>简单来说，这个问题最大的障碍是以下两点：</p>

<pre><code>    1.x86本身的架构不支持有虚拟机处理特定的硬件中断，也就是说，要不就让所有中断产生时
    直接陷入host，要不就让所有中断都由当前正在运行的虚拟机来处理；
    2.安全问题，如果让虚拟机能够随意直接处理硬件中断，那么会造成很多不可知的安全问题。
</code></pre>

<p>对于第一个问题，是由x86的specification定义的，除非改变整个x86架构，否则不会有本质的解决方案。那么，作者又是如何解决这个问题的呢？在这里，就像在virtual memory里的shadow page table一样，作者提出一个shadow IDT的概念。在解释这个shadow IDT之前，我想先介绍下x86虚拟化环境下的中断处理机制：</p>

<p><img src="http://ytliu.github.com/images/2012-01-04-2.png" title="interrupt handle in x86 virtualization" alt="x86 virtualization interrupt handling" /></p>

<pre><code>    由xen的机制举例，在整个系统中有两个IDT（Interrupt Descriptor Table），一个IDT由xen
    维护，一个由客户虚拟机维护，在一个硬件中断产生时，不管当前是xen在执行还是虚拟机在执
    行，都会先进入xen的IDT，由中断的vector相对应的handler进行处理，如果发现是由分配给虚
    拟机的硬件产生的中断，则有xen向虚拟机手动插入一个软件中断（software interrupt），当
    之后重新调度回虚拟机时会首先判断中断的flag是否有被置上，如果有某个vector的位被置上
    则先跳入相关的handler进行处理，处理完之后会向LAPIC（之前）或是x2APIC（现在）的相对应
    的EOI寄存器写入处理完成的标志，在写这个寄存器的同时，控制权会再次跳到xen，由xen对此
    进行模拟，告诉真实的硬件这个中断处理完成了。这是一个最简单的硬件处理过程，如果遇到当
    虚拟机在处理一个中断的时候又来了一个硬件中断，则会根据中断的优先级，或者这个中断是不
    是NMI等进行更加复杂的判断，这又是后话了。
</code></pre>

<p>那么shadow IDT又是怎么一回事呢？既然x86只支持两种模式的中断处理模式，那么ELI又是如何将特定的硬件中断交给客户虚拟机处理，而将其余的重新让xen进行处理的呢？整个流程简单来说是这样的：</p>

<pre><code>    ELI用的是第二种模式：当有硬件中断产生时，并不是直接陷入xen，而是跳到客户虚拟机的"IDT"，
    当然这个IDT不是客户虚拟机本身的IDT，而是由host在客户虚拟机启动时为其配置的shadow IDT，
    在这个IDT中，只有赋予客户虚拟机的设备（比如网卡）对应的中断处理函数是由意义的，而其它
    的entry则是被置上了一个NP（Non-present）位，也就是说，如果这个中断是由正确的中断产生的，
    则直接由客户虚拟机的handler处理，否则会向原来一样陷入xen，只是这次的陷入原因是NP，而不
    是像原来一样的中断原因。而在xen的NP处理时会判断这次的NP是不是由shadow IDT引起的，如果是
    则重新注入软中断，否则则按一般的NP（如page fault）进行处理。而对于EOI的写操作，ELI只支
    持x2APIC机制，因为在这个机制中可以设置相对应的bitmap来指定哪些寄存器的写需要陷入xen，由
    于这是可配置的，所以也就可以控制特定的硬件EOI直接由客户虚拟机处理而不需要陷入xen。这样
    就使得只有特定硬件产生的中断才会直接由客户虚拟机处理，其余的由host处理。但是这样并没有
    解决第二个问题：安全隐患。
</code></pre>

<p>对于第二个安全问题，有以下几点：</p>

<pre><code>    1.既然shadow IDT是存在客户虚拟机的地址空间的，那么用户就有能力去篡改里面的值，比如修改
    IDT的virtual-to-physical映射，将自己的恶意IDT映射上去从而实现某些攻击，比如将时间中断
    截获从而让虚拟机不能调度。对于这种攻击，一种方法是shadow所有的virtual-to-physical映射，
    但是这样会造成很大的性能损失，其他的方法是作者提出的preemption timer（在某个可配置的时
    间内强制陷入xen），或者是NMI和IDT limiting的结合（详见paper）；
    2.用户可以故意不写EOI寄存器，这个造成的危害是因为x86会自动屏蔽那些优先级小于正在被处理
    的中断的中断，所以它会影响host的interruptibility。对于这个问题，ELI会在每次陷入xen的时
    候，不过客户虚拟机有没有写EOI，就会自动模拟EOI的写操作，如果发现客户虚拟机确实还没有完
    成相对应的中断处理，则会进入injection mode，直到客户虚拟机进行了EOI的写。
</code></pre>

<hr />

<p>总的来说，这篇paper给我最大的收获是熟悉了x86及其虚拟化环境下的interrupt机制，它们用纯软件的方式实现了ExitLess Interrupt，而且得到了很好的评测结果，确实是一篇很有实力的paper。同时还要感谢Muli Ben-Yehuda教授和Nadav Amit学者的热心解答。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/12/26/paper-reading-tcp-re-and-incremental-mr/">Paper Reading: TCP RE and Incremental MR</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-12-26T20:57:00+08:00" pubdate data-updated="true">Dec 26<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>今天组会两篇paper，Naruil讲的第一篇听了蛮有收获的，DX讲的第二篇感觉是自己英文太差而且领域不熟最后听的不是很懂，就大致记录下吧。</p>

<p>第一篇是一个做数据中心之间数据传递重复消除的系统，叫End-to-end RE(redundancy elimination)，是发在NSDI&#8217;11上的，题目叫&#8221;EndRE: An End-System Redundancy Elimination Service for Enterprises&#8221;，主要由微软的人做的。简单来说它的motivation就是现在在网络中传递的数据有很大一部分是重复的，比如两个包有大量的重复数据，而这些重复数据占用了大量的带宽，而这篇paper的工作就是如何在减少重复数据的同时也不减少太多的性能。</p>

<p>现在在用的关于这种重复数据消除的技术主要是&#8221;Middlebox-based&#8221;，它有几个缺点：  <br/>
*       关于安全方面的问题，网络数据在middlebox里面是明文，这样才能更好地判断重复性，这样就势必减弱了网络数据的安全级别；    <br/>
*       对于一些终端的手机设备，它需要和PC终端传递数据，在这过程中同样有数据的重复，而这种情况就不适宜用Middlebox技术了；      <br/>
*       代价比较大，现在用的middlebox都是很强大的服务器，配备巨大的内存来存储内容的cache。</p>

<p>于是作者就提出一种end-to-end的RE技术。通篇听下来最大的收获是对传统的fingerprint算法和作者提出的一种新的SAMPLEBYTE fingerprint算法的理解。</p>

<p>这篇paper里面提到了两种传统的fingerprint算法：</p>

<pre><code>    ModP fingerprint：
            这是一种content-based的fingerprint算法，用一种特殊的hash算法
            （每一个window的hash值 = 上一个window的hash值+上一个window的第一个byte+下一个byte）
            这样可以快速地得出每个window的hash值，之后将该hash值mod一个P，
            如果结果为0，则将该hash值作为一个sample的fingerprint。             
    Fixed fingerprint：
            这是一个position-based的fingerprint算法，即每隔P个byte算一个hash
            （window size大小的byte），之后将其作为一个sample的fingerprint。
</code></pre>

<p>从这两个fingerprint算法可以很容易地看出对于ModP，由于它是一个content-based的算法，所以不管是不是有偏移都可以比较完整地得出内容上的重复性，但是它的效率太低了，因为它要算每一个byte的hash；而对于Fixed，它的效率远远大于ModP，但消除重复性的能力也相应地变小很多。</p>

<p>于是作者提出提出的一种新的算法，叫SAMPLEBYTE fingerprint：</p>

<pre><code>    提供一个256bit的数组A，遍历要发送的包的每一个字节，比如第一个字节是0x23，那么查找
    数组A的第23个bit看它是否为1，如果为0则表示miss，继续查看后一个字节，如果为1则代表hit，
    即将这个字节以及后window size个大小算一个hash作为fingerprint，然后跳过（p/2）个字节
    （为了防止计算重复的hit）。
</code></pre>

<p>也就是说SAMPLEBYTE也是一个content-based的算法，而且跳过了每个byte都要检查的低效率从而达到更合理而又大粒度的sample机制。</p>

<p>这是这篇paper的核心算法，至于最后如何利用得出的fingerprint，则可以通过下张图看出：</p>

<p><img src="http://ytliu.github.com/images/2011-12-26-1.png" title="the overview of EndRE" alt="RE Overview" />
<img src="http://ytliu.github.com/images/2011-12-26-2.png" title="Look up in fingerprint hash table" alt="Look up in fingerprint hash table" /></p>

<p>在服务器端和客户端都要维护一个同步的cache，同时在服务器端有一个hash table，里面的key即为之前算出来的fingerprint，指向的是cache中的offset，当要传递一个包时，将算出的fingerprint在hash table里面查找，如果hit了，则从该fingerprint的第一个byte开始找出最大匹配的字符长度，从而省去了该重复内容的传递。而在客户端也只需要将接收到的内容按时间顺序写入cache中，保持和服务器的cache的同步性就好了。</p>

<p>另外，这个数据重复性消除的问题还需要考虑的很重要的一点就是：在客户端不该有很复杂的计算，否则直接将包压缩传递岂不更高效？</p>

<p>还有关于fingerprint算法和差抄袭算法的关系，问了下Naruil，他之前写的差抄袭算法也是用了fingerprint，不过用的是一个更健壮性的fingerprint算法，是基于一篇Sigmod&#8217;03的paper：<a href="http://dl.acm.org/citation.cfm?id=872770">Winnowing</a>。有机会可以去瞻仰下，据说效果相当好，反正我们这里的抄袭都是这么被检查出来的~</p>

<hr />

<p>另外一篇的题目是&#8221;Incoop: MapReduce for Incremental Computation&#8221;，发表在Socc&#8217;11上，做的是MapReduce上的Incremental computation。也就是说现在的MR架构对于两个输入，即使是有许多重复的输入也是从头开始重新计算一遍，而作者希望的是对于两个输入，对于不变的输入可以不再重复计算，而仅仅是变化的数据。因为DX是用英文说的，很多内容不是搞得太懂，只知道它用了&#8221;content-base chunking&#8221;和&#8221;reduce combiners&#8221;来分别解决stability和granularity的问题。至于具体的细节就搞不来了。</p>

<hr />

<p>The End.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/12/23/paper-reading-mobile-security-survey-and-ds-failure-detection/">Paper Reading - Mobile Security Survey &amp; DS Failure Detection</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-12-23T13:38:00+08:00" pubdate data-updated="true">Dec 23<span>rd</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>今天考坑爹的专题讲座，昨天组会的paper reading只能拖到现在写了。  <br/>
先稍微提下为什么要有这个section吧~我一直觉得自己进PPI一年半，开过的组会听过的paper到现在为止大部分都不记得了，效率太尼玛低下了！于是乎我就想把自己一些比较有感触的paper整理下，至少忘得会慢些吧~</p>

<p>好了，废话结束。进入正题。</p>

<p>昨天讲了两篇paper，一篇是S&amp;P的security section的，Z神讲的，这篇其实和我们现在的方向挺相关的，不过确实没有任何创新，是一片完完全全的survey，title is</p>

<pre><code>    "Mobile Security Catching up? Revealing the Nuts and Boits of the Security of Mobile Devices"
</code></pre>

<p>作者是Michael Becher，它介绍了现在手机上存在的一些安全问题，包括和Desktop的比较，以及一些attack model，比如：</p>

<pre><code>    Hardware-centric attack
            MITM attack - 中间人攻击
            JTAG attack
            forensic attack - 没听懂。。。
    Device-independent - 和普通服务器上的攻击差不多
    Software-centric attack
    user layer attack
</code></pre>

<p>其中，关于JTAG attack,</p>

<blockquote><p>JTAG port is used for factory and field diagnostics and provides device-specific access to the internal flip-flops that store all the chip’s state.<br/>Since JTAG access gives the hardware equivalent of a software debugger, attackers have been using it from the beginning. The first attackers were probably competitors reverse engineering designs to copy them or improve their own. Currently, a packaged version of this attack has been in use for years to get free satellite TV.</p><footer><strong>@Nate Lawson</strong> <cite><a href='http://rdist.root.org/2007/04/06/jtag-attacks-and-pr-submarines'>rdist.root.org/2007/04/06/&hellip;</a></cite></footer></blockquote>


<p>还有关于Software-centric attack, 小Z讲了一个例子，比如说对iOS的pdf漏洞的良性利用，至于用来干嘛的，大家都懂得，jailbreak，不过其实我完全不知道这个是怎么样就得到root权限的，这几天研究下。</p>

<p>最后还有一点比较感兴趣的是小Z提到android的process isolation，我挺感兴趣的，它说android里面是用到context的概念进行进程间通讯，在kernel里面有一个binder进行管理，如果把kernel作为TPM那应该就没有什么安全问题了吧，不过其实还是存疑的，我不知道有没有一份关于android的安全机制的survey，上网搜了下，找到一篇宾大的&#8221;understand android security&#8221;，抽空看下。</p>

<p>其实这篇是一个完完全全的survey，小Z讲的也比较简单，不过其实手机的安全问题还是蛮多的，比如有提到的一个隐私的保护，有很多这方面的研究，比如通过限制控制流，比如TaintDroid，我想还有没有更强的机制呢？比如把Nicholai的histar用在手机上？</p>

<hr />

<p>另一篇是SOSP&#8217;11的</p>

<pre><code>    "Detecting Failures in Distributed Systems with the FALCON Spy Network"
</code></pre>

<p>其实是一篇想法很简单的paper，只不过之前的人没有把这个问题当做一个问题罢了。想法简单来说是这样的，现在在distributed system里面判断节点是否挂掉主要用的是end-to-end timeout机制，这样的缺点是发现节点挂掉可能会有比较长的延迟，比如说60s，那么在这60s里面机器A可能已经down掉了但却还被分配了任务从而造成availability变差，而这篇的目标就是：</p>

<pre><code>    Fast detection + reliability,
</code></pre>

<p>用的方法也很直接：gather inside information, avoid end-to-end timeout。相当于在运行应用程序主机的每一层跑一个spy（说白了就是和应用程序同个进程的一个线程），而每一层包括应用程序、OS、VMM，甚至是switch，用两个图就很容易理解：</p>

<p><img src="http://ytliu.github.com/images/2011-12-23-1.png" title="FALCON's Model" alt="FALCON's Model" />
<img src="http://ytliu.github.com/images/2011-12-23-2.png" title="FALCON's Implementation" alt="FALCON's Implementation" /></p>

<p>从后来的evaluation来看它的detection速度确实变小好多，CPU的overhead也很小，不过我觉得有两个问题：  <br/>
第一，在分布式系统中一台机器挂掉的几率可能很小，真的有必要为这么小的几率做一件这么复杂的事吗？比如原来是10秒钟检查到一个一个月才挂一次的机器现在用1秒钟来检查，却要付出一直用client和spy交互的代价？    <br/>
第二，如Model里每一层的spy都要和client端交互，那么网络带宽就要占用很多吧，为什么作者不测试网络带宽的占用率呢？CPU的overhead小可能是因为本来服务器的程序就不是CPU intensive的，但是确实IO intensive，那为什么不说下网络带宽被额外占用多少呢？还有，对于作者提出的架构来说，每一层spy与client的交互是走network的，如果用PV或HVM的话都得经过最下层的switch，那么按照作者的逻辑，既然其中一层的spy挂了就相当于全部挂了，那为什么不仅仅利用最下层的switch的spy提供的信息来判断呢？这样岂不是可以节省网络带宽？</p>

<p>The End.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/12/21/kai-pian-yi-shi/">开篇仪式</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-12-21T15:58:00+08:00" pubdate data-updated="true">Dec 21<span>st</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>其实很早就一直在想要写博客了，之前也尝试过（<a href="http://blog.csdn.net/microtrain016" title="microtrain016's blog">一只小小小鸟</a>），但是最后还是没有坚持下来。   <br/>
昨天看了鹏老大的一篇博文 - <a href="http://mindhacks.cn/2011/11/04/how-to-interview-a-person-for-two-years/">《怎样花两年时间去面试一个人》</a>，真的很有感触，其实我不能算一个geek，技术其实也挺一般的，在自己看来离人才还差得远，但是里面提到的&#8221;书单计划&#8221;和&#8221;github计划&#8221;应该是一个慢慢积累的过程，我还有半年的本科生涯，之后还有至少五年的博士，我没有要急于找工作的负担，为什么不趁这个最最珍贵的时间来积累呢？我一直相信于&#8221;厚积薄发&#8221;，还记得本科的时候看着自己与其他人的距离我写下&#8221;时间会拉近人与人之间的差距&#8221;，三年过去我觉得自己做到了一些，超过了一些当时在我心目中的牛人。但当我进入PPI，当我开始要考虑自己的博士生涯的时候发现，自己又成了一个更高层次的弱者，我为此感到兴奋，我未来的生活又可以在这种激情中度过，只是在这慢慢的积累中我希望看到一点一滴的进步，我很清楚自己在发散思维上的弱势，我急需一些方法提高。</p>

<p>我写博客是希望将自己在这个学习的过程中的感悟、收获以一种相比于记忆更不会消逝的方式记录下来，如果还能引起别人带来那么一丁点儿的共鸣那再好不过了，我从不祈求于自己能写出多么牛逼的技术文章，任何技术上的收获、生活中的感悟我都会记录下来，我从不认为文字分所谓的&#8221;贫贱贵富&#8221;，只要是自己的就是最真实的。</p>

<p>至于为什么要用Octopress+Github，是因为我们实验室的两个大牛（<a href="http://blog.yxwang.me">zellux</a>和<a href="http://chenyufei.info">ChenYufei</a>）都开始尝试着用了它，而且我也想感受用vi写博文的感觉所以就尝试写段时间，我希望这个尝试能一直进行下去。也希望能从中得到那些我希望得到的东西。</p>

<p>开篇结束，坚持是未来最大的挑战！</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/12/21/markdownyu-fa-ce-shi/">Markdown语法测试</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-12-21T15:17:00+08:00" pubdate data-updated="true">Dec 21<span>st</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="http://ytliu.github.com">http://ytliu.github.com</a></p>

<p>[mctrain](http://ytliu.github.com &#8220;mctrain&#8217;s blog&#8221;)  <br/>
<a href="http://ytliu.github.com" title="mctrain's blog">mctrain</a>  <br/>
<a href="http://ytliu.github.com" title="mctrain's blog">mctrain-2</a></p>

<pre><code>    ![pic](http://ytliu.github.com/images/search.png "pic")
</code></pre>

<p><img src="http://ytliu.github.com/images/search.png" title="pic" alt="pic" /></p>

<pre><code>    #title1
</code></pre>

<h1>title1</h1>

<pre><code>    ##title2
</code></pre>

<h2>title2</h2>

<pre><code>    ###title3
</code></pre>

<h3>title3</h3>

<pre><code>    ####title4
</code></pre>

<h4>title4</h4>

<pre><code>    #####title5
</code></pre>

<h5>title5</h5>

<pre><code>    ######title6
</code></pre>

<h6>title6</h6>

<pre><code>    *italic*
</code></pre>

<p><em>italic</em></p>

<pre><code>    **bold**
</code></pre>

<p><strong>bold</strong></p>

<pre><code>    ***italic&amp;bold***
</code></pre>

<p><strong><em>italic&amp;bold</em></strong></p>

<pre><code>    &gt;highlight
</code></pre>

<blockquote><p>highlight</p></blockquote>

<pre><code>    &lt;html&gt; *a* &lt;/html&gt;
</code></pre>

<p><html> <em>a</em> </html></p>

<ul>
<li>1</li>
<li>2</li>
<li><p>3</p></li>
<li><p>first</p></li>
<li>second</li>
<li>third</li>
<li>fourth</li>
</ul>


<p>hr-high</p>

<hr />

<p>hr-below</p>

<blockquote><p>highlight</p>

<blockquote><p>highlight again</p></blockquote></blockquote>

<p>{% codeblock %}
Awesome code snippet
{% endcodeblock %}</p>

<p>{% codeblock tang:objc %}
[rectangle setX: 10 y: 10 width: 20 height: 20];
{% endcodeblock %}</p>

<p>{% codeblock Javascript Array Syntax lang:js http://j.mp/pPUUmW MDN Documentation %}
var arr1 = new Array(arrayLength);
var arr2 = new Array(element0, element1, &#8230;, elementN);
{% endcodeblock %}</p>

<p>中文测试
这个测试中有很多很多很多字符
{% blockquote %}
&#8220;C&#8221;是系统默认的locale，&#8221;POSIX&#8221;是&#8221;C&#8221;的别名。所以当我们新安装完一个系统时，默认的locale就是C或POSIX。</p>

<p>在Debian中安装locales的方法如下：</p>

<p>· 通过apt-get install locales命令安装locales包
· 安装完成locales包后，系统会自动进行locale配置，你只要选择所需的locale，可以多选。最后指定一个系统默认的locale。这样系统就会帮你自动生成相应的locale和配置好系统的locale。</p>

<p>· 增加新的locale也很简单，用dpkg-reconfigure locales重新配置locale即可。</p>

<p>· 我们也可手动增加locale，只要把新的locale增加到/etc/locale.gen文件中，再运行locale-gen命令即可生成新的locale。再通过设置上面介绍的LC_*变量就可设置系统的locale了。下是一个locale.gen文件的样例。</p>

<p>UB的核心过程了。该过程之所以区分stage1.5和stage2，主要原因是GRUB和GRUB2的区别。在GRUB2中，将stage1.5过程集成到了stage2的过程中，所以stage1.5过程仅仅是针对GRUB的。下面将会分别介绍两种GRUB版本的两种过程。</p>

<p>4.1 GRUB中stage1.5过程</p>

<p>Stage1.5过程很无辜，它的作用很单一，但是非常关键。它的主要功用就是构造一个boot分区系统对应的文件系统，这样可以通过文件系统的路径（/boot/grub/）寻找stage2过程需要的core.img，进而加载到内存中开始执行。</p>

<p>Stage1.5存在于0面0道3扇区开始的地方，并一直延续十几k字节的区域，具体的大小与相应的文件系统的大小有关（文中涉及到了0面0道1-3+x扇区，这部分扇区为保留扇区，BIOS不会放置任何数据。正因为如此如果转换到GPT分区形式，系统将不能被正确引导，如上文所示，MBR后面的扇区都被其他内容所占据）。Stage1.5过程被构建成多种不同类型，但是功能类似，下面简单介绍一下基本的stage1.5过程的文件系统。e2fs_stage1_5（针对ext2fs，可引导ext2和ext3文件系统）、fat_stage1_5（针对fat文件系统，可引导fat32和fat16）、ffs_stage1_5、jfs_stage1_5、minix_stage1_5、reiserfs_stage1_5、vstafs_stage1_5和xfs_stage1_5，这些文件被称为stage1.5过程，这些文件每个至少都在11k以上。除此之外还有两个比较特殊的文件，分别为nbgrub和pxegrub，这两个文件主要是在网络引导时使用，只是格式不同而已，他们很类似与stage2，只是需要建立网络来获取配置文件。</p>

<p>由于stage1.5过程中会涉及到多个文件系统对应的文件，因此本文中主要以ext2fs为例进行说明，其他文件系统与此类似，可以同样进行分析理解。</p>

<p>对于ext2fs文件系统，用于生成该文件系统的stage1.5过程文件（e2fs_stage1_5）的代码为stage2/fsys_ext2fs.c文件。</p>

<p>在stage2/filesys.h文件中定义了每个文件系统对外的接口，用于上层调用，作为stage2过程寻找核心代码使用，文件系统一般被定义的接口主要就是三个函数，分别是mount、read和dir函数。对应ext2fs，其定义的函数为：</p>

<h1>ifdef FSYS_EXT2FS</h1>

<h1>define FSYS_EXT2FS_NUM 1</h1>

<p>int ext2fs_mount (void);
int ext2fs_read (char <em>buf, int len);
int ext2fs_dir (char </em>dirname);</p>

<h1>else</h1>

<h1>define FSYS_EXT2FS_NUM 0</h1>

<h1>endif</h1>

<p>针对ext2fs有如上的函数名称，每个函数将具体在stage2/fsys_ext2fs.c文件中被定义，这里面没有包含任何的写的过程，对于bootloader而言仅仅读就可以完成任务了，没必要对其系统进行写操作。其中ext2fs_mount函数用于检查文件系统类型，并将superblock读入到内存中；ext2fs_read函数和ext2fs_dir函数用于对文件系统具体的操作。在stage2/fsys_ext2fs.c文件中除了需要对这三个函数的定义之外，还需要文件系统的属性的数据结构（superblock、inode和group结构，这些结构最初被定义在include/linux/ext2_fs.h文件中），通过这些数据结构描述一个文件系统。</p>

<p>如果读者有兴趣可以试着创建新的文件系统的支持，可以参照目前存在的一些文件系统的模板（实例）编写。</p>

<p>4.2 GRUB中stage2过程</p>

<p>GRUB中的核心过程也就是stage2过程了，该过程主要是在文件系统建立以后选择合适的操作系统进行加载并转交控制权，达到最后引导操作系统的目标。由于GRUB属于multi boot loader，因此在引导的时候要进行选择，选择哪种操作系统来运行。在GRUB内部主要包括两种方式，首先是从menu.list中读取显示到屏幕让用户选择，其次是通过grub-shell中定义的命令手动进行启动。本文将在后面介绍这两种方式如何运行，接下来先介绍一下stage2的具体的执行过程。</p>

<p>在上面一节中介绍过，stage1.5过程中将boot分区的文件系统加载了，之后又做了一件事情，就是将控制权转交给stage2，而stage2入口的地方就是stage2/asm.S文件。Stage2/asm.S文件属于汇编代码，主要作用是初始化C语言的运行环境，为下面执行C语言的函数做好准备，在准备好之后，将执行init_bios_info(stage2/common.c)函数。init_bios_info函数的作用是执行一些底层的函数，然后跳转到cmain执行，cmain函数位于stage2/stage2.c文件中。cmain函数内部进行一个死循环，在循环内部首先加载配置文件，显示给用户，在这同时循环一个内层循环，在内层循环中，获取配置文件中的命令，并解析执行。过程中如果没有可用的配置文件，那么进入命令行模式（enter_cmdline函数），如果找到可用的menu，那么开始执行menu的对应的内容（run_menu函数）。</p>

<p>对于enter_cmdline（stage2/stage2.c）函数，将调用find_command（stage2/cmdline.c），进而执行相应命令的函数。</p>

<p>对于run_menu（stage2/stage2.c）函数，将调用stage2/cmdline.c文件中的run_script函数，进而调用find_command，执行相应命令的函数。</p>

<p>这两种方式虽然经过了不同的过程，对用户输入的行为进行分析和处理，最终调用的函数为find_command，在该函数中顺序循环比较“输入”的命令是否与系统内部定义的相同，如果相同转到执行该函数。在这个比较的过程中包含了一个全局的数据结构为struct builtin（stage2/shared.h），由该数据结构组成了一个table类型（stage2/builtins.c），将命令与相对应的builtin结构对应一起并进行串联。下面描述一下builtin结构的定义：</p>

<p>struct builtin</p>

<p>{</p>

<p>/<em> 命令名称，重要，是搜索命令时的依据</em>/</p>

<pre><code>char *name;

/* 命令函数，重要，是搜索匹配后调用的函数*/

int (*func) (char *, int);

/* 功能标示，一般未用到. */

int flags;

/* 简短帮助信息*/

char *short_doc;

/* 完整帮助信息*/

char *long_doc;
</code></pre>

<p>};</p>

<p>struct builtin *builtin_table[]；</p>

<p>有兴趣的读者可以对上面的内容进行扩展，形成自己的命令，主要在stage2/builtins.c文件中按照预定的格式更新，并添加到builtin_table中即可。</p>

<p>在上面打开配置文件的过程中，主要是通过一些文件操作函数（被定义在stage2/disk_io.c中）完成。这些文件操作函数主要包括：grub_open、grub_read、grub_seek和grub_close等，这些函数属于grub对外的上层接口，具体的函数内部将调用前文中提到的boot分区对应的文件系统的相应的函数完成，这个过程主要是通过回调函数来完成。该过程整体思路类似于面向对象过程，通过对象操作具体的函数。关于用C语言实现面向对象的编程思路，可以参考一本书——《Object-oriented Programming with ANSI-C》。</p>

<p>4.3))}))))</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/page/3/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2013/02/17/%5B%28zhuan-%29%5D-ji-suan-ji-de-qi-dong/">【转】计算机的启动</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/01/12/qiao-bang-zhu-chuan-you-gan/">乔帮主传有感</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/01/06/base64bian-ma/">Base64编码</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/12/30/qemu-study-for-android-emulator/">Qemu study for Android emulator</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/12/20/ru-guo-ming-tian-shi-shi-jie-mo-ri/">如果明天是世界末日</a>
      </li>
    
  </ul>
</section>


<section>
  <h1>Latest Tweets</h1>
  <ul id="tweets">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  <script type="text/javascript">
    $.domReady(function(){
      getTwitterFeed("microtrain016", 4, false);
    });
  </script>
  <script src="/javascripts/twitter.js" type="text/javascript"> </script>
  
    <a href="http://twitter.com/microtrain016" class="twitter-follow-button" data-show-count="false">Follow @microtrain016</a>
  
</section>



<section class="googleplus">
  <h1>
    <a href="https://plus.google.com/mctrain016@gmail.com?rel=author">
      <img src="http://www.google.com/images/icons/ui/gprofile_button-32.png" width="32" height="32">
      Google+
    </a>
  </h1>
</section>



  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2013 - Liu Yutao -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  





  <script type="text/javascript">
    (function() {
      var script = document.createElement('script'); script.type = 'text/javascript'; script.async = true;
      script.src = 'https://apis.google.com/js/plusone.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(script, s);
    })();
  </script>



  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
